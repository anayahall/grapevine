{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINI TEST\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import shapely as shp\n",
    "import geopandas as gpd\n",
    "\n",
    "import pulp\n",
    "import scipy as sp\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "# from matplotlib import rc\n",
    "\n",
    "os.chdir(\"/Users/anayahall/projects/grapevine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# FUNCTIONS IN THIS SCRIPT\n",
    "\n",
    "# define function to convert into proj in meters\n",
    "def epsg_meters(gdf, proj=26911):\n",
    "    g = gdf.copy()\n",
    "    g = g.to_crs(epsg=proj)\n",
    "    return g\n",
    "\n",
    "# define function to get dictionary names for LP\n",
    "def get_dict_names(dict):\n",
    "    names = []\n",
    "    for key, value in dict.items():\n",
    "    #     print(key)\n",
    "        names.append(key)\n",
    "    return names\n",
    "\n",
    "# function to make array of coordinates to calculate matrices\n",
    "def geo_to_coords(df):\n",
    "    df['coord'] = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "    #      print('index', index)\n",
    "    #      print('row', row)\n",
    "         for pt in list(row['geometry'].coords): \n",
    "    #         print(pt)\n",
    "            df.at[index,'coord'] = np.asarray(pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini gdfs of county wastes (tbm - location and MSW for 2014) \n",
    "c_proj = gpd.read_file(\"data/clean/techbiomass_pts.shp\")\n",
    "\n",
    "#CONVERT TO METERS!!\n",
    "c = epsg_meters(c_proj)\n",
    "\n",
    "#c = c[(c['biomass.ca'] == \"organic fraction municipal solid waste\") & (c['year'] == 2014)].copy()\n",
    "c = c[(c['biomass.fe'] == \"FOOD\") & (c['year'] == 2014)].copy()\n",
    "\n",
    "c = c[['FIPS', 'COUNTY', 'disposal.y', 'geometry']]\n",
    "# subset out four counties\n",
    "csub = c[(c['COUNTY'] == \"Los Angeles\") | (c['COUNTY'] == \"San Diego\")| \n",
    "         (c['COUNTY'] == \"Orange\")| (c['COUNTY'] == \"Imperial\")].copy()\n",
    "# csub = c[(c['COUNTY'] == \"San Diego\")| (c['COUNTY'] == \"Imperial\")].copy()\n",
    "# csub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Imperial': 6751.16711032454,\n",
       " 'Los Angeles': 307295.084575734,\n",
       " 'Orange': 104525.755860299,\n",
       " 'San Diego': 113139.59859294}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####MAKE DICTIONARY HERE\n",
    "cdict = dict(zip(csub['COUNTY'], csub['disposal.y']))\n",
    "cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini gdfs of facilites (location and capacity)\n",
    "f_proj = gpd.read_file(\"data/clean/clean_swis.shp\")\n",
    "# f.head(8)\n",
    "\n",
    "f = epsg_meters(f_proj)\n",
    "\n",
    "f = f[['SwisNo', 'AcceptedWa', 'County', 'cap_m3', 'geometry']].copy()\n",
    "\n",
    "# subset out four counties\n",
    "fsub = f[(f['County'] == \"Los Angeles\") | (f['County'] == \"San Diego\") | \n",
    "          (f['County'] == \"Orange\")| (f['County'] == \"Imperial\")].copy()\n",
    "# too many, just select first 5\n",
    "fsub = fsub[0:5].copy()\n",
    "fdict = dict(zip(fsub['SwisNo'], fsub['cap_m3'])) #alt is use SwisNo\n",
    "\n",
    "\n",
    "facnames = get_dict_names(fdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type C:  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# CREATE DISTANCE MATRIX #################################\n",
    "\n",
    "# RUN ON subset gdfs\n",
    "geo_to_coords(csub)\n",
    "geo_to_coords(fsub)\n",
    "\n",
    "# Make coords into list for cost-distance matrix\n",
    "C = list(csub.coord)\n",
    "F = list(fsub.coord)\n",
    "\n",
    "print(\"type C: \", type(C))\n",
    "\n",
    "# test1 = pd.DataFrame(distance_matrix(C, F), index = csub.COUNTY, columns = fsub.SwisNo)\n",
    "cost_distance = list(distance_matrix(C,F))\n",
    "\n",
    "# cost_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK distances to make sure they're in the right place?? - this test STILL IN DEGREES!\n",
    "# import math\n",
    "# C1 = [-118.57205925,   34.14803912]\n",
    "# F3 = [-117.1805,   32.8622]\n",
    "# distance = math.sqrt( ((C1[0]-F3[0])**2)+((C1[1]-F3[1])**2) )\n",
    "# print(\"distance between cty 1(LA) and fac 3(37AB): \", distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "Route_Imperial_13_AA_0095 = 6751.0\n",
      "Route_Imperial_19_AA_1060 = 0.0\n",
      "Route_Imperial_19_AR_5584 = 0.0\n",
      "Route_Imperial_30_AB_0378 = 0.0\n",
      "Route_Imperial_37_AB_0011 = 0.0\n",
      "Route_Los_Angeles_13_AA_0095 = 48052.0\n",
      "Route_Los_Angeles_19_AA_1060 = 0.0\n",
      "Route_Los_Angeles_19_AR_5584 = 0.0\n",
      "Route_Los_Angeles_30_AB_0378 = 0.0\n",
      "Route_Los_Angeles_37_AB_0011 = 0.0\n",
      "Route_Orange_13_AA_0095 = 0.0\n",
      "Route_Orange_19_AA_1060 = 9174.0\n",
      "Route_Orange_19_AR_5584 = 33823.0\n",
      "Route_Orange_30_AB_0378 = 7645.0\n",
      "Route_Orange_37_AB_0011 = 7645.0\n",
      "Route_San_Diego_13_AA_0095 = 0.0\n",
      "Route_San_Diego_19_AA_1060 = 0.0\n",
      "Route_San_Diego_19_AR_5584 = 0.0\n",
      "Route_San_Diego_30_AB_0378 = 0.0\n",
      "Route_San_Diego_37_AB_0011 = 0.0\n",
      "Total Cost of Transportation =  52286531073.82747\n"
     ]
    }
   ],
   "source": [
    "#FIRST RUN TEST - BASED ON BEER DISTRIBUTION EXAMPLE\n",
    "# Import PuLP modeler functions\n",
    "from pulp import *\n",
    "\n",
    "# Creates a list of all the supply nodes\n",
    "Counties  = [\"Imperial\", \"Los Angeles\", \"Orange\", \"San Diego\"]\n",
    "\n",
    "# Creates a dictionary for the number of units of supply for each supply node\n",
    "waste = cdict\n",
    "\n",
    "# Creates a list of all demand nodes\n",
    "Facilities = facnames\n",
    "\n",
    "# Creates a dictionary for the number of units of demand for each demand node\n",
    "compost = fdict\n",
    "\n",
    "# Creates a list of costs of each transportation path\n",
    "costs = cost_distance\n",
    "\n",
    "# The cost data is made into a dictionary\n",
    "costs = makeDict([Counties, Facilities],costs,0)\n",
    "\n",
    "emfac = 1.8\n",
    "\n",
    "# Creates the 'prob' variable to contain the problem data\n",
    "prob = LpProblem(\"Compost Distribution Problem\",LpMaximize)\n",
    "\n",
    "# Creates a list of tuples containing all the possible routes for transport\n",
    "Routes = [(c,f) for c in Counties for f in Facilities]\n",
    "\n",
    "# A dictionary called 'Vars' is created to contain the referenced variables(the routes)\n",
    "vars = LpVariable.dicts(\"Route\",(Counties,Facilities),0,None,LpInteger)\n",
    "\n",
    "# The objective function is added to 'prob' first\n",
    "prob += lpSum([vars[c][f]*costs[c][f]*emfac for (c,f) in Routes]), \"Sum_of_Transporting_Costs\"\n",
    "\n",
    "# # The supply maximum constraints are added to prob for each supply node (warehouse)\n",
    "for c in Counties:\n",
    "    prob += lpSum([vars[c][f] for f in Facilities])<=waste[c], \"Sum_of_waste_out_of_Counties_%s\"%c\n",
    "\n",
    "# The demand minimum constraints are added to prob for each demand node (bar)\n",
    "for f in Facilities:\n",
    "    prob += lpSum([vars[c][f] for c in Counties])<=compost[f], \"Sum_of_compost_into_Facilities_%s\"%f\n",
    "\n",
    "# vars \n",
    "# The problem data is written to an .lp file\n",
    "prob.writeLP(\"CompostDistributionProblem.lp\")\n",
    "\n",
    "# The problem is solved using PuLP's choice of Solver\n",
    "prob.solve()\n",
    "\n",
    "# The status of the solution is printed to the screen\n",
    "print(\"Status:\", LpStatus[prob.status])\n",
    "\n",
    "# Each of the variables is printed with it's resolved optimum value\n",
    "for v in prob.variables():\n",
    "    print(v.name, \"=\", v.varValue)\n",
    "\n",
    "# The optimised objective function value is printed to the screen    \n",
    "print(\"Total Cost of Transportation = \", value(prob.objective))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52286531.07382747\n"
     ]
    }
   ],
   "source": [
    "# print(value(prob.objective)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "Route_('Chicago',_'Gary') = 4000.0\n",
      "Route_('Chicago',_'Tempe') = 2000.0\n",
      "Route_('Cincinatti',_'Albany') = 2000.0\n",
      "Route_('Cincinatti',_'Houston') = 3000.0\n",
      "Route_('Kansas_City',_'Houston') = 4000.0\n",
      "Route_('Kansas_City',_'Tempe') = 2000.0\n",
      "Route_('Pittsburgh',_'Chicago') = 3000.0\n",
      "Route_('Pittsburgh',_'Cincinatti') = 2000.0\n",
      "Route_('Pittsburgh',_'Gary') = 2000.0\n",
      "Route_('Pittsburgh',_'Kansas_City') = 3000.0\n",
      "Route_('Youngstown',_'Albany') = 1000.0\n",
      "Route_('Youngstown',_'Chicago') = 3000.0\n",
      "Route_('Youngstown',_'Cincinatti') = 3000.0\n",
      "Route_('Youngstown',_'Kansas_City') = 3000.0\n",
      "Total Cost of Transportation =  15005.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The American Steel Problem for the PuLP Modeller\n",
    "Authors: Antony Phillips, Dr Stuart Mitchell  2007\n",
    "\"\"\"\n",
    "\n",
    "# Import PuLP modeller functions\n",
    "from pulp import *\n",
    "\n",
    "# List of all the nodes\n",
    "Nodes = [\"Youngstown\",\n",
    "         \"Pittsburgh\",\n",
    "         \"Cincinatti\",\n",
    "         \"Kansas City\",\n",
    "         \"Chicago\",\n",
    "         \"Albany\",\n",
    "         \"Houston\",\n",
    "         \"Tempe\",\n",
    "         \"Gary\"]\n",
    "\n",
    "nodeData = {# NODE        Supply Demand\n",
    "         \"Youngstown\":    [10000,0],\n",
    "         \"Pittsburgh\":    [15000,0],\n",
    "         \"Cincinatti\":    [0,0],\n",
    "         \"Kansas City\":   [0,0],\n",
    "         \"Chicago\":       [0,0],\n",
    "         \"Albany\":        [0,3000],\n",
    "         \"Houston\":       [0,7000],\n",
    "         \"Tempe\":         [0,4000],\n",
    "         \"Gary\":          [0,6000]}\n",
    "\n",
    "# List of all the arcs\n",
    "Arcs = [(\"Youngstown\",\"Albany\"),\n",
    "        (\"Youngstown\",\"Cincinatti\"),\n",
    "        (\"Youngstown\",\"Kansas City\"),\n",
    "        (\"Youngstown\",\"Chicago\"),\n",
    "        (\"Pittsburgh\",\"Cincinatti\"),\n",
    "        (\"Pittsburgh\",\"Kansas City\"),\n",
    "        (\"Pittsburgh\",\"Chicago\"),\n",
    "        (\"Pittsburgh\",\"Gary\"),\n",
    "        (\"Cincinatti\",\"Albany\"),\n",
    "        (\"Cincinatti\",\"Houston\"),\n",
    "        (\"Kansas City\",\"Houston\"),\n",
    "        (\"Kansas City\",\"Tempe\"),\n",
    "        (\"Chicago\",\"Tempe\"),\n",
    "        (\"Chicago\",\"Gary\")]\n",
    "\n",
    "arcData = { #      ARC                Cost Min Max\n",
    "        (\"Youngstown\",\"Albany\"):      [0.5,0,1000],\n",
    "        (\"Youngstown\",\"Cincinatti\"):  [0.35,0,3000],\n",
    "        (\"Youngstown\",\"Kansas City\"): [0.45,1000,5000],\n",
    "        (\"Youngstown\",\"Chicago\"):     [0.375,0,5000],\n",
    "        (\"Pittsburgh\",\"Cincinatti\"):  [0.35,0,2000],\n",
    "        (\"Pittsburgh\",\"Kansas City\"): [0.45,2000,3000],\n",
    "        (\"Pittsburgh\",\"Chicago\"):     [0.4,0,4000],\n",
    "        (\"Pittsburgh\",\"Gary\"):        [0.45,0,2000],\n",
    "        (\"Cincinatti\",\"Albany\"):      [0.35,1000,5000],\n",
    "        (\"Cincinatti\",\"Houston\"):     [0.55,0,6000],\n",
    "        (\"Kansas City\",\"Houston\"):    [0.375,0,4000],\n",
    "        (\"Kansas City\",\"Tempe\"):      [0.65,0,4000],\n",
    "        (\"Chicago\",\"Tempe\"):          [0.6,0,2000],\n",
    "        (\"Chicago\",\"Gary\"):           [0.12,0,4000]}\n",
    "\n",
    "# Splits the dictionaries to be more understandable\n",
    "(supply, demand) = splitDict(nodeData)\n",
    "(costs, mins, maxs) = splitDict(arcData)\n",
    "\n",
    "# Creates the boundless Variables as Integers\n",
    "vars = LpVariable.dicts(\"Route\",Arcs,None,None,LpInteger)\n",
    "\n",
    "# Creates the upper and lower bounds on the variables\n",
    "for a in Arcs:\n",
    "    vars[a].bounds(mins[a], maxs[a])\n",
    "\n",
    "# Creates the 'prob' variable to contain the problem data    \n",
    "prob = LpProblem(\"American Steel Problem\",LpMinimize)\n",
    "\n",
    "# Creates the objective function\n",
    "prob += lpSum([vars[a]* costs[a] for a in Arcs]), \"Total Cost of Transport\"\n",
    "\n",
    "# Creates all problem constraints - this ensures the amount going into each node is at least equal to the amount leaving\n",
    "for n in Nodes:\n",
    "    prob += (supply[n]+ lpSum([vars[(i,j)] for (i,j) in Arcs if j == n]) >=\n",
    "             demand[n]+ lpSum([vars[(i,j)] for (i,j) in Arcs if i == n])), \"Steel Flow Conservation in Node %s\"%n\n",
    "\n",
    "# The problem data is written to an .lp file\n",
    "prob.writeLP(\"AmericanSteelProblem.lp\")\n",
    "\n",
    "# The problem is solved using PuLP's choice of Solver\n",
    "prob.solve()\n",
    "\n",
    "# The status of the solution is printed to the screen\n",
    "print(\"Status:\", LpStatus[prob.status])\n",
    "\n",
    "# Each of the variables is printed with it's resolved optimum value\n",
    "for v in prob.variables():\n",
    "    print(v.name, \"=\", v.varValue)\n",
    "\n",
    "# The optimised objective function value is printed to the screen    \n",
    "print(\"Total Cost of Transportation = \", value(prob.objective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
